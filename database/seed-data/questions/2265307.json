{
  "id": "/questions/2265307",
  "creationDate": "2014-02-18T02:40:05.390",
  "body": "\n\nI have a table with 4 columns and N rows. At the beginning N will be around 1000 and will have tendency to grow up to 3000.\n* 1st: string unique\n* 2nd: int with N/5 unique values\n* 3rd: int with 5 unique values\n* 4th: data value\n\nThe objective is to get to the value of the 4th column with different queries, ex: \"get the value, where the 1st column is 17\", or: \"get all values where the 2nd column is 7\", or: \"does any row has this data\". ~40% of queries will be done against the 4th column, ~30% against 3rd, ~20% 2nd and ~10% for 1st.\n\nSince there would be around 100 queries per second, and around 2 changes (add/update/remove) per second against this table, I was wondering, what would be the fastest way (in C#) to manage this data? Memory is not an issue\n\nI'm currently using a SortedDictionary, where the key is the 4th data value; and the dictionary's value is a class containing the first three values. Verifying the \"4th column\" is now easy by just using ContainsKey; and when querying by other values I use:\n\n\tforeach(var object in Objects) if(Objects[Data].2nd==object.Value.2nd) {...}\n\t\n\nAny suggestions appreciated.",
  "lastActivityDate": "2014-03-07T07:23:49.063",
  "title": "Optimizing a small table of data for best search (query) speed",
  "tags": [
    "c#",
    "table",
    "data",
    "performance"
  ],
  "docScore": 0,
  "comments": [],
  "answers": [],
  "creationYearMonth": "201403",
  "itemTally": 0,
  "owner": null
}